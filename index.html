<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI for the Arts</title>
    <style>
        /* CSS Styles */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background-color: #f5f5f5;
            color: #333;
            line-height: 1.6;
        }

        header {
            background-color: #2c3e50;
            color: white;
            padding: 1rem 0;
            text-align: center;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        nav {
            background-color: #34495e;
            padding: 0.5rem 0;
        }

        nav ul {
            display: flex;
            justify-content: center;
            list-style: none;
        }

        nav ul li {
            margin: 0 1rem;
        }

        nav ul li a {
            color: white;
            text-decoration: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            transition: background-color 0.3s;
        }

        nav ul li a:hover {
            background-color: #2c3e50;
        }

        .container {
            max-width: 1200px;
            margin: 2rem auto;
            padding: 0 1rem;
        }

        .page {
            background-color: white;
            border-radius: 8px;
            padding: 2rem;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
            margin-bottom: 2rem;
            display: none;
        }

        .page.active {
            display: block;
        }

        h1, h2, h3 {
            color: #2c3e50;
            margin-bottom: 1rem;
        }

        h1 {
            font-size: 2.5rem;
        }

        h2 {
            font-size: 2rem;
            border-bottom: 2px solid #eee;
            padding-bottom: 0.5rem;
            margin-bottom: 1.5rem;
        }

        h3 {
            font-size: 1.5rem;
            margin-top: 1.5rem;
        }

        p {
            margin-bottom: 1rem;
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 1rem auto;
            border: 1px solid #ddd;
            border-radius: 4px;
            box-shadow: 0 2px 5px rgba(0,0,0,0.1);
        }

        .image-container {
            text-align: center;
            margin: 2rem 0;
        }

        .image-description {
            background-color: #f9f9f9;
            padding: 1rem;
            border-radius: 4px;
            margin-top: 1rem;
        }

        .pdf-viewer {
            width: 100%;
            height: 600px;
            border: 1px solid #ddd;
            border-radius: 4px;
            margin: 1rem 0;
        }

        .upload-container {
            background-color: #f9f9f9;
            padding: 2rem;
            border-radius: 4px;
            border: 2px dashed #ccc;
            text-align: center;
            margin: 2rem 0;
        }

        .upload-container:hover {
            border-color: #2c3e50;
        }

        .btn {
            background-color: #3498db;
            color: white;
            border: none;
            padding: 0.5rem 1rem;
            border-radius: 4px;
            cursor: pointer;
            font-size: 1rem;
            transition: background-color 0.3s;
        }

        .btn:hover {
            background-color: #2980b9;
        }

        footer {
            background-color: #2c3e50;
            color: white;
            text-align: center;
            padding: 1rem 0;
            margin-top: 2rem;
        }

        @media (max-width: 768px) {
            nav ul {
                flex-direction: column;
                align-items: center;
            }
            
            nav ul li {
                margin: 0.5rem 0;
            }
            
            .pdf-viewer {
                height: 400px;
            }
        }
    </style>
</head>
<body>
    <header>
        <h1>AI for the Arts</h1>
    </header>

    <nav>
        <ul>
            <li><a href="#" onclick="showPage('home')">Home</a></li>
	    <li><a href="#" onclick="showPage('Image0')">Getting Data</a></li>
	    <li><a href="#" onclick="showPage('image3')">MNIST Data</a></li>
	    <li><a href="#" onclick="showPage('image2')">Testing Data</a></li>
            <li><a href="#" onclick="showPage('image1')">Handwritten Classification</a></li>
            <li><a href="#" onclick="showPage('image4')">Pre-trained Model</a></li>
            <li><a href="#" onclick="showPage('pdf')">Project PDF</a></li>
        </ul>
    </nav>

    <div class="container">
        <!-- Home Page -->
        <div id="home" class="page active">
            <h2>Welcome to AI-For-Arts Coursework</h2>
            <p>This website showcases various aspects of a machine learning project, including model training results, data analysis, and architecture details.</p>
            
            <h3>Project Overview</h3>
            <p>The project involves working with the MNIST dataset for handwritten digit classification, using both custom convolutional neural networks and pre-trained models like VGG19.</p>
            
            <h3>Navigation</h3>
            <p>Use the menu above to explore different aspects of the project:</p>
            <ul>
                <li><strong>Handwritten Classification:</strong> Training metrics and results</li>
                <li><strong>Testing Data:</strong> Stratified sampling information</li>
                <li><strong>MNIST Data:</strong> Information about the dataset</li>
                <li><strong>Pre-trained Model:</strong> VGG19 architecture details</li>
                <li><strong>Project PDF:</strong> View and upload the complete project documentation</li>
            </ul>
        </div>

        <!-- Image 1 Page -->
        <div id="image1" class="page">
            <h2>Handwritten Classification Results</h2>
            
            <div class="image-container">
                <img src="Hand Written Classification .png" alt="Handwritten Classification Results">
                <div class="image-description">
                    <h3>Model Training Metrics</h3>
                    <p>This image shows the training progress of a convolutional neural network for handwritten digit classification on the MNIST dataset.</p>
                    <p>The model achieves:</p>
                    <ul>
                        <li>Training accuracy: 99.23%</li>
                        <li>Validation accuracy: 99.26%</li>
                        <li>Training loss: 0.0219</li>
                        <li>Validation loss: 0.0439</li>
                    </ul>
                    <p>The bottom array [0.872, 0.8607, ...] represents cross-validation accuracy scores across 10 folds when using an SGD classifier for comparison.</p>
                </div>
            </div>
        </div>

        <!-- Image 2 Page -->
        <div id="image2" class="page">
            <h2>Setting Aside Testing Data</h2>
            
            <div class="image-container">
                <img src="Setting Aside the Testing Data.png" alt="Testing Data Distribution">
                <div class="image-description">
                    <h3>Stratified Sampling</h3>
                    <p>This image demonstrates the distribution of a stratified sample based on income categories for housing data.</p>
                    <p>The distribution shows:</p>
                    <ul>
                        <li>Category 3: 35.05%</li>
                        <li>Category 2: 31.88%</li>
                        <li>Category 4: 17.64%</li>
                        <li>Category 5: 11.43%</li>
                        <li>Category 1: 4.00%</li>
                    </ul>
                    <p>Stratified sampling ensures that the test set is representative of the overall distribution of important features.</p>
                </div>
            </div>
        </div>

        <!-- Image 3 Page -->
        <div id="image3" class="page">
            <h2>MNIST Dataset Information</h2>
            
            <div class="image-container">
                <img src="Downloading the Data Image .png" alt="MNIST Dataset Information">
                <div class="image-description">
                    <h3>MNIST Dataset Details</h3>
                    <p>The MNIST dataset contains 70,000 handwritten digit images (28x28 pixels) with 784 features each.</p>
                    <p>Key points:</p>
                    <ul>
                        <li>Digits are size-normalized and centered</li>
                        <li>Training set: 60,000 examples</li>
                        <li>Test set: 10,000 examples</li>
                        <li>Originally from NIST, processed by Yann LeCun et al.</li>
                        <li>Common benchmark for classification algorithms</li>
                    </ul>
                    <p>The bottom array shows sample labels from the dataset ('5', '0', '4', etc.).</p>
                </div>
            </div>
        </div>

        <!-- Image 4 Page -->
        <div id="image4" class="page">
            <h2>Pre-trained VGG19 Model</h2>
            
            <div class="image-container">
                <img src="Pre-trained Model.png" alt="VGG19 Model Architecture">
                <div class="image-description">
                    <h3>VGG19 Architecture</h3>
                    <p>This image shows the initial layers of the VGG19 convolutional neural network architecture.</p>
                    <p>Key features:</p>
                    <ul>
                        <li>Input: 224Ã—224 RGB images</li>
                        <li>Initial conv layers with 64 filters</li>
                        <li>Max pooling reduces spatial dimensions</li>
                        <li>Number of filters doubles after each pooling</li>
                        <li>Total parameters: 143,667,240 (548MB)</li>
                    </ul>
                    <p>VGG19 is a deep CNN with 19 weight layers, widely used for image classification tasks.</p>
                </div>
            </div>
        </div>

        <!-- PDF Page -->
        <div id="pdf" class="page">
            <h2>Project Documentation</h2>
            
            <div class="upload-container">
                <h3>Upload Project PDF</h3>
                <input type="file" id="pdf-upload" accept=".pdf">
                <button class="btn" onclick="loadPDF()">View PDF</button>
            </div>
            
            <div id="pdf-display">
                <h3>Current Project PDF</h3>
                <embed id="pdf-viewer" class="pdf-viewer" src="machine learning.pdf" type="application/pdf">
                <p>The PDF contains complete documentation of the machine learning project, including:</p>
                <ul>
                    <li>Data loading and preprocessing steps</li>
                    <li>Model architecture details</li>
                    <li>Training procedures</li>
                    <li>Evaluation metrics</li>
                    <li>Comparison with other methods</li>
                </ul>
            </div>
        </div>
    </div>

    <footer>
        <p>&copy; 2023 Machine Learning Project Showcase. All rights reserved.</p>
    </footer>

    <script>
        // JavaScript for page navigation
        function showPage(pageId) {
            // Hide all pages
            const pages = document.querySelectorAll('.page');
            pages.forEach(page => {
                page.classList.remove('active');
            });
            
            // Show selected page
            document.getElementById(pageId).classList.add('active');
        }

        // Function to handle PDF upload
        function loadPDF() {
            const fileInput = document.getElementById('pdf-upload');
            const file = fileInput.files[0];
            
            if (file) {
                const reader = new FileReader();
                
                reader.onload = function(e) {
                    const pdfViewer = document.getElementById('pdf-viewer');
                    pdfViewer.src = e.target.result;
                };
                
                reader.readAsDataURL(file);
            } else {
                alert('Please select a PDF file first.');
            }
        }
    </script>
</body>
</html>